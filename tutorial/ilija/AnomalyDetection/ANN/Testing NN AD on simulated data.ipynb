{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Neural Network based Anomaly Detection on simulated data\n",
    "\n",
    "#### This code generates large dataframe containing multiple timeseries, randomly adds changes in both mean and variance (anomalies), tries to train neural network to distinguish measurements belonging to the timebin under investigation from measurements in a reference time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "from pandas.tseries.offsets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parameters to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(17)\n",
    "\n",
    "# parameters of simulated data generation\n",
    "n_series = 5\n",
    "start_date = '2017-08-01 00:00:00'\n",
    "end_date = '2017-08-07 23:59:59'\n",
    "\n",
    "# regular behaviour\n",
    "max_noise_amplitude = 0.05 # all the timeseries will have values between 0 and 1\n",
    "\n",
    "# anomalies\n",
    "p_anomaly = 2 * 10E-6\n",
    "max_anomaly_duration = 4*3600 # 4 h\n",
    "\n",
    "\n",
    "# lenghts of subject and reference time periods\n",
    "refh = 12\n",
    "subh = 1\n",
    "\n",
    "# probability to correctly classify sample based purely on luck\n",
    "chance = refh/(subh+refh)\n",
    "# how much better than luck we want to be to say we detected an anomaly. Default is 5%\n",
    "cut = chance + (1-chance) * 0.05\n",
    "\n",
    "print('chance:',chance, '\\tcut:', cut)\n",
    "ref = refh * Hour()\n",
    "sub = subh * Hour()\n",
    "\n",
    "# number of training epochs \n",
    "epochs=60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dti=pd.DatetimeIndex(start=start_date,end=end_date, freq='s')\n",
    "n_timesteps = len(dti)\n",
    "df = pd.DataFrame()\n",
    "for s in range(n_series):\n",
    "    v = np.random.normal(random.random()/2, max_noise_amplitude/random.randint(10, 80), n_timesteps) \n",
    "    df['link '+str(s)] = pd.Series(v)\n",
    "df['Flag']=0\n",
    "df['score']=0.5\n",
    "df.index = dti\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_anomalies():\n",
    "    to_generate = int(n_timesteps * p_anomaly)\n",
    "    for a in range(to_generate):\n",
    "        affects = random.sample(range(n_series), random.randint(1, n_series))\n",
    "        duration = int(max_anomaly_duration * random.random())\n",
    "        start = int(n_timesteps * random.random())\n",
    "        end = min(start+duration, n_timesteps)\n",
    "        print('affected:', affects, df.iloc[start].name, df.iloc[end].name)\n",
    "        for s in affects:\n",
    "            df.iloc[start:end,s] = df.iloc[start:end,s] + random.random() * 0.2\n",
    "        df.iloc[start:end,n_series]=1\n",
    "        \n",
    "random_anomalies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### enforce range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df<0] = 0\n",
    "df[df>1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(figsize=(10,3.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=n_series*2, input_shape=(n_series,), activation='relu' ))\n",
    "#         model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=n_series*2, activation='relu'))    \n",
    "#         model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid') )\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',optimizer='rmsprop', metrics=['accuracy'])\n",
    "#         model.compile(loss='hinge', optimizer='sgd', metrics=['binary_accuracy'])\n",
    "#         model.compile(loss='mse',optimizer='rmsprop', metrics=['accuracy'])\n",
    "#         model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['binary_accuracy'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def plotHist(hist):\n",
    "    es=len(hist.history['loss'])\n",
    "    x = np.linspace(0,es-1,es)\n",
    "    plt.plot(x, hist.history['loss'], '--', linewidth=2, label='loss')\n",
    "    plt.plot(x, hist.history['acc'], '-', linewidth=2, label='acc')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_for_anomaly(ref, sub, count):\n",
    "    \n",
    "    y_ref = pd.DataFrame([0] * ref.shape[0])\n",
    "    y_ref.index=ref.index\n",
    "    X_ref=ref\n",
    "    del X_ref['Flag']\n",
    "    del X_ref['score']\n",
    "    \n",
    "    y_sub = pd.DataFrame([1] * sub.shape[0])\n",
    "    y_sub.index=sub.index\n",
    "    X_sub=sub\n",
    "    del X_sub['Flag']\n",
    "    del X_sub['score']\n",
    "    \n",
    "    # separate Reference and Subject into Train and Test\n",
    "    X_ref_train, X_ref_test, y_ref_train, y_ref_test = train_test_split(X_ref, y_ref, test_size=0.3, random_state=42)\n",
    "    X_sub_train, X_sub_test, y_sub_train, y_sub_test = train_test_split(X_sub, y_sub, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # combine training ref and sub samples\n",
    "    X_train = pd.concat([X_ref_train, X_sub_train])\n",
    "    y_train = pd.concat([y_ref_train, y_sub_train])\n",
    "\n",
    "    # combine testing ref and sub samples\n",
    "    X_test = pd.concat([X_ref_test, X_sub_test])\n",
    "    y_test = pd.concat([y_ref_test, y_sub_test])\n",
    "    \n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    \n",
    "    X_train_s, y_train_s = shuffle(X_train, y_train)\n",
    "    \n",
    "    m=getModel()\n",
    "    hist = m.fit(X_train_s.values, y_train_s.values, epochs=epochs, verbose=0, shuffle=True, batch_size=256)\n",
    "\n",
    "    \n",
    "    loss_and_metrics = m.evaluate(X_test.values, y_test.values)#, batch_size=256)\n",
    "    #print(loss_and_metrics)\n",
    "\n",
    "    if loss_and_metrics[1] > cut:# or not count%5: \n",
    "        plotHist(hist)\n",
    "        \n",
    "    return loss_and_metrics[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping over time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find min and max timestamps\n",
    "\n",
    "start = df.index.min()\n",
    "end = df.index.max()\n",
    "\n",
    "#round start \n",
    "start.seconds=0\n",
    "start.minutes=0\n",
    "\n",
    "\n",
    "# loop over them\n",
    "ti=start+ref+sub\n",
    "count=0\n",
    "while ti < end + 1 * Minute():\n",
    "    print(count)\n",
    "    startt = time()\n",
    "    ref_start = ti-ref-sub\n",
    "    ref_end = ti-sub\n",
    "    ref_df = df[(df.index >= ref_start) & (df.index < ref_end)]\n",
    "    sub_df = df[(df.index >= ref_end) & (df.index < ti)]\n",
    "    score = check_for_anomaly(ref_df, sub_df, count)\n",
    "    df.loc[(df.index>=ref_end) & (df.index<=ti),['score']] = score\n",
    "    print('\\n',ti,\"\\trefes:\" , ref_df.shape[0], \"\\tsubjects:\", sub_df.shape[0], '\\tscore:', score)\n",
    "    ti = ti + sub\n",
    "    count=count+1\n",
    "    endt=time()\n",
    "    print(\"took:\", endt-startt)\n",
    "#     if count>2: break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(figsize=(20,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "df.loc[:,'Detected'] = 0\n",
    "df.loc[df.score>cut,'Detected']=1\n",
    "df.head()\n",
    "ax.plot(df.Flag, 'r')\n",
    "ax.plot(df.score,'g')\n",
    "ax.fill( df.Detected, 'b', alpha=0.3)\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
